{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atomic-approach",
   "metadata": {},
   "source": [
    " ## Exercise 43 - Bike Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "brief-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPathReadings = \"/data/students/bigdata-01QYD/ex_data/Ex43/data/readings.txt\"\n",
    "inputPathNeighbors = \"/data/students/bigdata-01QYD/ex_data/Ex43/data/neighbors.txt\"\n",
    "\n",
    "outputPath = \"out_Ex43/\"\n",
    "outputPath2 = \"out_Ex43_2/\"\n",
    "outputPath3 = \"out_Ex43_3/\"\n",
    "\n",
    "threshFreeSlots = 3\n",
    "threshCriticalPercentage = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-truth",
   "metadata": {},
   "source": [
    "__Input__ : \n",
    "\n",
    "* A textual csv file containing the occupancy of the stations of a bike sharing system. Each line of the file contains one sensor reading/sample has the following format (stationId,date,hour,minute,num_of_bikes,num_of_free_slots). Some readings are missing due to temporarily malfunctions of the stations. Hence, the number of samplings is not exactly the same for all stations. The number of distinct stations is 100.\n",
    "\n",
    "* A second textual csv file containing the list of  neighbors of each station. Each line of the file has the following format stationIdx, list of neighbors of stationIdx."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-williams",
   "metadata": {},
   "source": [
    "__Output__ : \n",
    "\n",
    "1. A file containing one line for each question. Each line contains a question and the list of answers to that question (QuestionId, TextOfTheQuestion, list of Answers).\n",
    "   * A station is in a critical situation if the number of free slots is below a user provided threshold (e.g., 3 slots)\n",
    "   *  The percentage of critical situations for a station Si is defined as (number of critical readings associated with Si)/(total number of readings associated with Si) \n",
    "   \n",
    "2. Store in an HDFS file the stations with a percentage of critical situations higher than 80%  (i.e., stations that are almost always in a critical situation and need to be extended)\n",
    "    * Each line of the output file is associated with one of the selected stations and contains the percentage of critical situations and the stationId. Sort the stored stations by percentage of critical situations\n",
    "\n",
    "3. Compute the percentage of critical situations for each pair (timeslot, station)\n",
    "    * Timeslot can assume the following 6 values : [0-3],[4-7],[8-11],[12-15],[16-19],[20-23]\n",
    "    \n",
    "4. Store in an HDFS file the pairs (timeslot, station) with a percentage of critical situations higher than  80% (i.e., stations that need rebalancing operations in specific timeslots)\n",
    "    * Each line of the output file is associated with one of the selected pairs (timeslot, station) and contains the percentage of critical situations and the pair (timeslot, stationId). Sort the result by percentage of critical situations\n",
    "    \n",
    "5. Select a reading (i.e., a line) of the first input file if and only if the following constraints are true\n",
    "    * The line is associated with a full station situation. \n",
    "    * All the neighbor stations of the station Si are full in the time stamp associated with the current line\n",
    "  \n",
    "6.  Store the selected readings/lines in an HDFS file and print on the standard output the total number of such lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "valued-maine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s1,2015-05-01,00,00,5,4',\n",
       " 's2,2015-05-01,00,00,4,4',\n",
       " 's3,2015-05-01,00,00,6,3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readingsRDD = sc.textFile(inputPathReadings)\n",
    "readingsRDD.collect()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sweet-colors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s1,s2 s3', 's2,s1 s5', 's3,s1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborsRDD = sc.textFile(inputPathNeighbors)\n",
    "neighborsRDD.collect()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-cigarette",
   "metadata": {},
   "source": [
    "__2__ :  HDFS file the stations with a percentage of critical situations higher than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "certain-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', (0, 1)), ('s2', (0, 1)), ('s3', (0, 1))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall : the number of free slots is the last element\n",
    "\n",
    "def mapReadings(line):\n",
    "    elements = line.split(\",\")\n",
    "    \n",
    "    # critical value\n",
    "    if int(elements[-1]) < threshFreeSlots:\n",
    "        return (elements[0], (1,1))\n",
    "    else:\n",
    "        return (elements[0], (0,1))\n",
    "        \n",
    "\n",
    "# map elements \n",
    "# (sId, (x,y))\n",
    "#    x = keep track of the critical situations\n",
    "#    y = keep track of the total number or readings\n",
    "pairsReadingsRDD = readingsRDD.map(mapReadings)\n",
    "pairsReadingsRDD.collect()[:3]                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "municipal-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', 0.2), ('s3', 0.4), ('s2', 0.25), ('s4', 1.0), ('s5', 0.2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the critical value ratio\n",
    "# 1. sum the values by key\n",
    "# 2. compute the ratio CriticalSitutations/TotalReadings\n",
    "criticalPercentagesRDD = pairsReadingsRDD.reduceByKey(lambda pair1, pair2 : (pair1[0] + pair2[0], pair1[1] + pair2[1]) )\\\n",
    "                                         .mapValues(lambda pair : pair[0] / pair[1] )\n",
    "criticalPercentagesRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "governing-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s4', 1.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the stations with a criticalPercentage above threshold\n",
    "# order them in a decreasing order\n",
    "criticalStationsRDD = criticalPercentagesRDD.filter(lambda pair : pair[1] > threshCriticalPercentage)\\\n",
    "                                            .sortBy(lambda pair : pair[1], ascending=False)\n",
    "criticalStationsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticalStationsRDD.saveAsTextFile(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-softball",
   "metadata": {},
   "source": [
    "__2__ : Compute the percentage of critical situations for each pair (timeslot, station).\n",
    "\n",
    "Timeslot can assume the following 6 values : [0-3],[4-7],[8-11],[12-15],[16-19],[20-23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "premier-solomon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('s1', '[0-3]'), (0, 1)),\n",
       " (('s2', '[0-3]'), (0, 1)),\n",
       " (('s3', '[0-3]'), (0, 1))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_mapping = {\n",
    "    \"[0-3]\" : [0,1,2,3],\n",
    "    \"[4-7]\" : [4,5,6,7],\n",
    "    \"[8-11]\" : [8,9,10,11],\n",
    "    \"[12-15]\" : [12,13,14,15],\n",
    "    \"[16-19]\" : [16,17,18,19],\n",
    "    \"[20-23]\" : [20,21,22,23]\n",
    "}\n",
    "\n",
    "def mapReadingsV2(line):\n",
    "    elements = line.split(\",\")\n",
    "    \n",
    "    hour = int(elements[2])\n",
    "    pair_key = \"\"\n",
    "    \n",
    "    # get pair key \n",
    "    # aka timeslot\n",
    "    for k in dic_mapping:\n",
    "        if hour in dic_mapping[k]:\n",
    "            pair_key = k\n",
    "    \n",
    "    # critical value\n",
    "    if int(elements[-1]) < threshFreeSlots:\n",
    "        return ( (elements[0],pair_key), (1,1))\n",
    "    else:\n",
    "        return ( (elements[0],pair_key), (0,1))\n",
    "        \n",
    "\n",
    "# map elements \n",
    "# (sId, (x,y))\n",
    "#    x = keep track of the critical situations\n",
    "#    y = keep track of the total number or readings\n",
    "pairsTimeSlotsRDD = readingsRDD.map(mapReadingsV2)\n",
    "pairsTimeSlotsRDD.collect()[:3]                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "alpine-reputation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('s4', '[0-3]'), 1.0), (('s4', '[12-15]'), 1.0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as before\n",
    "criticalPercentagesV2RDD = pairsTimeSlotsRDD.reduceByKey(lambda pair1, pair2 : (pair1[0] + pair2[0], pair1[1] + pair2[1]) )\\\n",
    "                                            .mapValues(lambda pair : pair[0] / pair[1] )\\\n",
    "                                            .filter(lambda pair : pair[1] > threshCriticalPercentage)\\\n",
    "                                            .sortBy(lambda pair : pair[1], ascending=False)\n",
    "criticalPercentagesV2RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "entitled-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticalStationsRDD.saveAsTextFile(outputPath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-valentine",
   "metadata": {},
   "source": [
    "__5__ : Select a reading (i.e., a line) of the first input file if and only if the following constraints are true\n",
    "\n",
    "* The line is associated with a full station situation.\n",
    "* All the neighbor stations of the station Si are full in the time stamp associated with the current line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "previous-guest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s1', ['s2', 's3']),\n",
       " ('s2', ['s1', 's5']),\n",
       " ('s3', ['s1']),\n",
       " ('s4', ['s5']),\n",
       " ('s5', ['s4', 's2'])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## from the professor\n",
    "\n",
    "# Map each line of the input file to a pair stationid, list of neighbor stations\n",
    "nPairRDD = neighborsRDD.map(lambda line: (line.split(\",\")[0], line.split(\",\")[1].split(\" \")) )\n",
    "nPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hidden-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local dictionary in the main memory of the driver that will be used to store the mapping \n",
    "# stationid -> list of neighbors\n",
    "# There are only 100 stations. Hence, you can suppose that data about neighbors can be stored in the main memory\n",
    "neighbors=nPairRDD.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cutting-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the lines/readings associated with a full status (number of free slots equal to 0)\n",
    "fullStatusLines = readingsRDD.filter(lambda line: int(line.split(\",\")[5])==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "communist-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTimestamp(reading):\n",
    "    fields = reading.split(\",\")\n",
    "    timestamp = fields[1] + fields[2] + fields[3]\n",
    "    \n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eastern-fluid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2015-05-020000', 's1,2015-05-02,00,00,9,0'),\n",
       " ('2015-05-020000', 's2,2015-05-02,00,00,8,0'),\n",
       " ('2015-05-020000', 's3,2015-05-02,00,00,9,0')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an RDD of pairs with key = timestamp and value=reading associated with that timestamp\n",
    "# The concatenation of fields[1], fields[2], fields[3] is the timestamp of the reading\n",
    "fullLinesPRDD = fullStatusLines.map(lambda reading: (extractTimestamp(reading), reading))\n",
    "fullLinesPRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "military-compound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2015-05-020000',\n",
       "  ['s1,2015-05-02,00,00,9,0',\n",
       "   's2,2015-05-02,00,00,8,0',\n",
       "   's3,2015-05-02,00,00,9,0'])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Collapse all the values with the same key in one single pair (timestamp, reading associated with that timestamp)\n",
    "fullReadingsPerTimestamp = fullLinesPRDD.groupByKey()\n",
    "fullReadingsPerTimestamp.mapValues(lambda v: list(v)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "outdoor-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectReadingssFunc(pairTimeStampListReadings):\n",
    "    # Extract the list of stations that appear in the readings\n",
    "    # associated with the current key \n",
    "    # (i.e., the list of stations that are full in this timestamp)\n",
    "    # The list of readings is in the value part of the inpput key-value pair\n",
    "    stations = []\n",
    "    for reading in pairTimeStampListReadings[1]:\n",
    "        # Extract the stationid from each reading\n",
    "        fields = reading.split(\",\")\n",
    "        stationId = fields[0]\n",
    "        stations.append(stationId)\n",
    "        \n",
    "        \n",
    "    # Iterate again over the list of readings to select the readings satistying the constraint on the \n",
    "    # full status situation of all neighboors \n",
    "    selectedReading = []\n",
    "\n",
    "    for reading in pairTimeStampListReadings[1]:\n",
    "        # This reading must be selected if all the neighbors of\n",
    "        # the station of this reading are also in the value of\n",
    "        # the current key-value pair (i.e., if they are in list stations)\n",
    "        # Extract the stationid of this reading\n",
    "        fields = reading.split(\",\")\n",
    "        stationId = fields[0]\n",
    "\n",
    "        # Select the list of neighbors of the current station\n",
    "        nCurrentStation = neighbors[stationId]\n",
    "        \n",
    "        # Check if all the neighbors of the current station are in value \n",
    "        # (i.e., the local list stations) of the current key-value pair\n",
    "        allNeighborsFull = True\n",
    "        \n",
    "        for neighborStation in nCurrentStation:\n",
    "            if neighborStation not in stations:\n",
    "                # There is at least one neighbor of th current station\n",
    "                # that is not in the full status in this timestamp\n",
    "                allNeighborsFull = False\n",
    "                \n",
    "        if allNeighborsFull == True:\n",
    "            selectedReading.append(reading)\n",
    "            \n",
    "    return selectedReading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "exact-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each pair contains a timestamp and the list of readings (with number of free slots equal to 0) \n",
    "# associated with that timestamp.\n",
    "# Check, for each reading in the list, if all the neighbors of the station of that reading are \n",
    "# also present in this list of readings\n",
    "# Emit one \"string\" for each reading associated with a completely full status \n",
    "selectedReadingsRDD = fullReadingsPerTimestamp.flatMap(selectReadingssFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "burning-arrest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s1,2015-05-02,00,00,9,0', 's3,2015-05-02,00,00,9,0']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedReadingsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
