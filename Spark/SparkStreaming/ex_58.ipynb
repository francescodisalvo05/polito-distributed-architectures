{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effective-atlantic",
   "metadata": {},
   "source": [
    "## Exercise 58 - Identification\n",
    "\n",
    "Reading : stationId,#freeslots,#usedslots,timestamp\n",
    "\n",
    "For each reading with a number of free slots equal to 0, print on the standard output the timestamp and the station id. \n",
    "Emit the results every two seconds, considering only the data sent on the last two seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "activated-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the spark object that wait for the \n",
    "# information every two seconds\n",
    "ssc = StreamingContext(sc,2)\n",
    "\n",
    "# the stream will be connected to localhost\n",
    "# through port 9999\n",
    "linesDStream = SocketTextStream(\"localhost\",9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |-- line : stationId,#freeslots,#usedslots,timestamp\n",
    "\n",
    "# get just the lines with #freeslots = 0\n",
    "filteredDStream = linesDStream.filter(lambda line : line.split(\",\")[1] == \"0\")\n",
    "\n",
    "# get timestamp and stationId\n",
    "stationIdTimestampDStream = filteredDStream.map(lambda line : (line.split(\",\")[0],line.split(\",\")[2]))\n",
    "\n",
    "# print on the standard otput the first 10 elements\n",
    "stationIdTimestampDStream.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start reading the incoming data\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stay alive for at most 90 seconds\n",
    "ssc.awaitTerminationOrTimeout(90)\n",
    "# stop only the StreamingContext\n",
    "# but not the SparkContext\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
