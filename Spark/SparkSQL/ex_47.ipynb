{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regular-convergence",
   "metadata": {},
   "source": [
    " ## Exercise 47 - Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surprising-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "inputPath = \"/data/students/bigdata-01QYD/ex_data/Ex47/data\"\n",
    "outputPathV1 = \"res_out_Ex47V1/\"\n",
    "outputPathV2 = \"res_out_Ex47V2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-article",
   "metadata": {},
   "source": [
    "__input__ : \n",
    "* A CSV file containing a list of user profiles : _name, age, gender_\n",
    "\n",
    "__output__ : \n",
    "*  Select male users (gender=“male”), increase by one their age, and store in the output folder name and age of these users sorted by decreasing age and ascending name (if the age value is the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-manchester",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excess-smith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+------+\n",
      "| name|age|gender|\n",
      "+-----+---+------+\n",
      "| Paul| 40|  male|\n",
      "|David| 15|  male|\n",
      "|Susan| 40|female|\n",
      "|Karen| 34|female|\n",
      "| John| 40|  male|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# map into (movieid , userid)\n",
    "df = spark.read.load(inputPath, format=\"csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sexual-essay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|newage|\n",
      "+-----+------+\n",
      "| John|    41|\n",
      "| Paul|    41|\n",
      "|David|    16|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.filter('gender=\"male\"')\n",
    "df_filtered_updated = df_filtered.selectExpr(\"name\", \"age+1 as newage\")\n",
    "df_filtered_updated_sorted = df_filtered_updated.sort(\"age\", \"name\", ascending=[False,True])\n",
    "df_filtered_updated_sorted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aware-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_updated_sorted.write.csv(outputPathV1, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-ghost",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bacterial-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.read.load(inputPath, format=\"csv\", header=True, inferSchema=True)\n",
    "df_sql.createOrReplaceTempView(\"people\")\n",
    "\n",
    "df_sql_updated = spark.sql(\"\"\"  SELECT name, age+1 as newage\n",
    "                                FROM people\n",
    "                                WHERE gender='male'\n",
    "                                SORT BY age desc, name\n",
    "                            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "impressive-ladder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|newage|\n",
      "+-----+------+\n",
      "| John|    41|\n",
      "| Paul|    41|\n",
      "|David|    16|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql_updated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "equal-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_updated.write.csv(outputPathV2, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
